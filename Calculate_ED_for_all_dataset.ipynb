{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XU5-zf5Ad3k3"
      },
      "source": [
        "After observing the yahoo finance package, found some days' closing price are not correct. So, the extra script help to fix the data. There is no need to download and fix manully everytime. I already email to the yahoo finance to fix this data. If they fix, then there will be no use of this first script in future.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xi5GaAFCD3eJ",
        "outputId": "312ae444-72fd-4795-8192-21e97c047516"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading EUR/USD data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2381738963.py:8: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  df = yf.download(ticker, start=\"2000-01-01\", progress=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Flattening columns...\n",
            "\n",
            "Applying corrections...\n",
            "Fixing 2008-01-08: Old=1.5571 -> New=1.4705\n",
            "Fixing 2008-02-08: Old=1.5571 -> New=1.4503\n",
            "Fixing 2008-08-08: Old=1.5049 -> New=1.5074\n",
            "Fixing 2008-09-08: Old=1.5050 -> New=1.4250\n",
            "Fixing 2008-10-08: Old=1.4957 -> New=1.3650\n",
            "Fixing 2008-12-08: Old=1.4918 -> New=1.2930\n",
            "\n",
            "Done. Saved to EURUSD_Close_Fixed.csv\n"
          ]
        }
      ],
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "\n",
        "def download_and_fix_eurusd_close():\n",
        "    # Download EUR/USD data\n",
        "    print(\"Downloading EUR/USD data...\")\n",
        "    ticker = \"EURUSD=X\"\n",
        "    df = yf.download(ticker, start=\"2000-01-01\", progress=False)\n",
        "\n",
        "    df = df[['Close']].copy()\n",
        "\n",
        "    # Flatten columns if multi-index (common in yfinance)\n",
        "    if isinstance(df.columns, pd.MultiIndex):\n",
        "        print(\"Flattening columns...\")\n",
        "        df.columns = df.columns.get_level_values(0)\n",
        "\n",
        "    # Taken from https://www.kaggle.com/datasets/lehenzehra/eurusd-daily-data-ohlc?select=EURUSD_D1_Sorted.csv\n",
        "    corrections = {\n",
        "        \"2008-01-08\": 1.4705,\n",
        "        \"2008-02-08\": 1.4503,\n",
        "        \"2008-08-08\": 1.5074,\n",
        "        \"2008-09-08\": 1.4250,\n",
        "        \"2008-10-08\": 1.3650,\n",
        "        \"2008-12-08\": 1.2930,\n",
        "    }\n",
        "\n",
        "    print(\"\\nApplying corrections...\")\n",
        "\n",
        "    # Apply corrections\n",
        "    for date_str, price in corrections.items():\n",
        "        dt = pd.Timestamp(date_str)\n",
        "        if dt in df.index:\n",
        "            print(f\"Fixing {date_str}: Old={df.at[dt, 'Close']:.4f} -> New={price:.4f}\")\n",
        "            df.at[dt, 'Close'] = price\n",
        "        else:\n",
        "            print(f\"Warning: {date_str} not found in data.\")\n",
        "\n",
        "\n",
        "    # Save to CSV\n",
        "    output_file = \"EURUSD_Close_Fixed.csv\"\n",
        "    df.to_csv(output_file)\n",
        "    print(f\"\\nDone. Saved to {output_file}\")\n",
        "\n",
        "\n",
        "download_and_fix_eurusd_close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKtUL89vecY7"
      },
      "source": [
        "Load the corrected data and make a 'difference' percentafge column based on the closing price."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "2vHKLCk2Px_2"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"EURUSD_Close_Fixed.csv\", index_col=0, parse_dates=True)\n",
        "df['difference'] = df['Close'].pct_change() * 100\n",
        "df.head()\n",
        "df.to_csv('EURUSD_Close_Fixed_with_difference.csv')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtUAKNsQeqt4"
      },
      "source": [
        "The main script started from here. Creating main data table for calculating Euclidean Distane."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82ea1b91",
        "outputId": "9f67906a-68da-4a40-c92a-5ee2ff50b8eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved 'main_data_table.csv'.\n"
          ]
        }
      ],
      "source": [
        "data = df['difference'].dropna().tolist()\n",
        "\n",
        "main_data_rows = []\n",
        "window_size = 6\n",
        "\n",
        "# Iterate through the data to create feature vectors and target values\n",
        "for i in range(len(data) - window_size + 1):\n",
        "    row = data[i : i + window_size]\n",
        "    feature_vector = row[:5]\n",
        "    true_value = row[5]\n",
        "    main_data_rows.append(feature_vector + [true_value])\n",
        "\n",
        "# Create column names for the new DataFrame\n",
        "column_names = [f'p{j+1}' for j in range(5)] + ['true_value_next_day']\n",
        "\n",
        "# Create the 'main_data' DataFrame\n",
        "main_data = pd.DataFrame(main_data_rows, columns=column_names)\n",
        "\n",
        "# Set the DataFrame index to start from 1\n",
        "main_data.index = range(1, len(main_data) + 1)\n",
        "\n",
        "#Saving \"Main Data Table\"\n",
        "main_data.to_csv('main_data_table.csv', index_label='Vectors')\n",
        "print(\"Saved 'main_data_table.csv'.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qoz5ePjde70h"
      },
      "source": [
        "After forming the \"difference\" column as vectors, calcultaing the Euclidean Distance. And do statics of the positive and negative outcomes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aoqDsVKMXsCf",
        "outputId": "29a3b9e1-f93a-4e2c-a45d-cf67bc40a8fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Started at => 2025-12-26 23:33:37.501559\n",
            "\n",
            "-----Calculating Euclidean Distance-----\n",
            "\n",
            "T: --> 0.5--> 0.6--> 0.7--> 0.8--> 0.9--> 1.0--> 1.1--> 1.2--> 1.3--> 1.4--> 1.5\n",
            "Results Different THRESHOLDS:\n",
            "Finished at => 2025-12-26 23:53:25.701384\n",
            "Total time take => 0:19:48.199825\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "#Create base_vector range -2 to 2, each time take 5 datapoints for a vectors.\n",
        "generated_base_vectors = np.random.uniform(low=-2.0, high=2.0, size=(50, 5))\n",
        "\n",
        "\n",
        "final_results = []\n",
        "start_time = datetime.now()\n",
        "print(f\"Started at => {start_time}\")\n",
        "print(f\"\\n-----Calculating Euclidean Distance-----\\n\")\n",
        "print(\"T: \", end=\"\")\n",
        "for current_threshold in np.arange(0.5, 1.51, 0.1):\n",
        "    print(f\"--> {current_threshold:.1f}\", end=\"\")\n",
        "    accepted_results_list = []\n",
        "\n",
        "    # Iterate through each generated base vector\n",
        "    for gen_base_vec_idx in range(generated_base_vectors.shape[0]):\n",
        "        current_base_vector = generated_base_vectors[gen_base_vec_idx]\n",
        "        base_vectors_for_each_threshold = []\n",
        "\n",
        "        for index, row in main_data.iterrows():\n",
        "            feature_vector = np.array(row[['p1', 'p2', 'p3', 'p4', 'p5']].tolist())\n",
        "            euclidean_distance = np.linalg.norm(feature_vector - current_base_vector)\n",
        "            v_target = 0;\n",
        "\n",
        "            if euclidean_distance < current_threshold:\n",
        "                v_target = row['true_value_next_day']\n",
        "                if current_base_vector.tolist() not in base_vectors_for_each_threshold:\n",
        "                    base_vectors_for_each_threshold.append(current_base_vector.tolist())\n",
        "\n",
        "                accepted_results_list.append({\n",
        "                    'r1': feature_vector.tolist(),\n",
        "                    'v_target': v_target,\n",
        "              })\n",
        "\n",
        "        if accepted_results_list and base_vectors_for_each_threshold: # Check if the list is not empty\n",
        "            accepted_results_df = pd.DataFrame(accepted_results_list)\n",
        "            positive_count = (accepted_results_df['v_target'] > 0).sum()\n",
        "            negative_count = (accepted_results_df['v_target'] <= 0).sum()\n",
        "            positive_percentage=(positive_count/len(accepted_results_df))*100\n",
        "            negative_percentage=(negative_count/len(accepted_results_df))*100\n",
        "            r1_values = accepted_results_df['r1']\n",
        "            v_target_values = accepted_results_df['v_target']\n",
        "\n",
        "            final_results.append({\n",
        "                'r1': r1_values.tolist(),\n",
        "                'v_target': v_target_values.tolist(),\n",
        "                'B': base_vectors_for_each_threshold,\n",
        "                'threshold': f\"{current_threshold:.1f}\",\n",
        "                '% positive_Vtarget': f\"{positive_percentage:.2f}\",\n",
        "                '% negative_Vtarget': f\"{negative_percentage:.2f}\"\n",
        "            })\n",
        "\n",
        "final_result_df = pd.DataFrame(final_results)\n",
        "print(\"\\nResults Different THRESHOLDS:\")\n",
        "final_result_df.to_csv('final_result_df.csv', index= True)\n",
        "end_time = datetime.now()\n",
        "print(f\"Finished at => {end_time}\")\n",
        "print(f\"Total time take => {end_time - start_time}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}